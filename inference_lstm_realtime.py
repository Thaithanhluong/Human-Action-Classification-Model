import cv2
import mediapipe as mp
import numpy as np
import threading
import tensorflow as tf
import os

# âœ… 1. Tá»± Ä‘á»™ng láº¥y danh sÃ¡ch hÃ nh Ä‘á»™ng tá»« dá»¯ liá»‡u
def get_Actions(data_dir="./data"):
    """Láº¥y danh sÃ¡ch cÃ¡c hÃ nh Ä‘á»™ng tá»« thÆ° má»¥c dá»¯ liá»‡u"""
    if not os.path.exists(data_dir):
        print(f"âš ï¸ ThÆ° má»¥c {data_dir} khÃ´ng tá»“n táº¡i! Sá»­ dá»¥ng danh sÃ¡ch máº·c Ä‘á»‹nh.")
        return []

    unique_actions = sorted([d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))])
    
    if not unique_actions:
        print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y hÃ nh Ä‘á»™ng nÃ o trong thÆ° má»¥c dá»¯ liá»‡u!")
    
    return unique_actions

# âœ… 2. Láº¥y danh sÃ¡ch hÃ nh Ä‘á»™ng tá»« thÆ° má»¥c
actions = get_Actions("./data")
if not actions:
    actions = ['UNKNOWN']  # Náº¿u khÃ´ng cÃ³ dá»¯ liá»‡u, Ä‘áº·t nhÃ£n máº·c Ä‘á»‹nh

print("ğŸ“Œ Danh sÃ¡ch hÃ nh Ä‘á»™ng:", actions)

# âœ… 3. Khá»Ÿi táº¡o Mediapipe & Model
label = "Warmup..."
n_time_steps = 10
lm_list = []

mpPose = mp.solutions.pose
pose = mpPose.Pose()
mpDraw = mp.solutions.drawing_utils

# Táº£i mÃ´ hÃ¬nh
try:
    model = tf.keras.models.load_model("./model/model_v1.keras")
except Exception as e:
    print(f"âŒ KhÃ´ng thá»ƒ táº£i mÃ´ hÃ¬nh: {e}")
    exit()

cap = cv2.VideoCapture(0)

def make_landmark_timestep(results):
    """TrÃ­ch xuáº¥t cÃ¡c Ä‘áº·c trÆ°ng tá»« khung xÆ°Æ¡ng"""
    c_lm = []
    for lm in results.pose_landmarks.landmark:
        c_lm.extend([lm.x, lm.y, lm.z, lm.visibility])
    return c_lm

def draw_landmark_on_image(mpDraw, results, img):
    """Váº½ cÃ¡c Ä‘iá»ƒm má»‘c lÃªn áº£nh"""
    mpDraw.draw_landmarks(img, results.pose_landmarks, mpPose.POSE_CONNECTIONS)
    h, w, _ = img.shape
    for lm in results.pose_landmarks.landmark:
        cx, cy = int(lm.x * w), int(lm.y * h)
        cv2.circle(img, (cx, cy), 5, (255, 0, 0), cv2.FILLED)
    return img

def draw_class_on_image(label, img):
    """Váº½ nhÃ£n dá»± Ä‘oÃ¡n lÃªn áº£nh"""
    cv2.putText(img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
    return img

def detect(model, lm_list):
    """Nháº­n diá»‡n hÃ nh Ä‘á»™ng tá»« mÃ´ hÃ¬nh"""
    global label
    lm_list = np.array(lm_list)
    lm_list = np.expand_dims(lm_list, axis=0)
    results = model.predict(lm_list, verbose=0)
    max_index = np.argmax(results[0])
    label = actions[max_index] if max_index < len(actions) else "UNKNOWN"
    return label

# âœ… 4. Cháº¡y vÃ²ng láº·p webcam
i = 0
warmup_frames = 60

while True:
    success, img = cap.read()
    if not success:
        print("âŒ Lá»—i khi Ä‘á»c webcam!")
        break

    imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = pose.process(imgRGB)
    
    i += 1
    if i > warmup_frames:
        if results.pose_landmarks:
            c_lm = make_landmark_timestep(results)
            lm_list.append(c_lm)
            if len(lm_list) == n_time_steps:
                threading.Thread(target=detect, args=(model, lm_list)).start()
                lm_list = []

            img = draw_landmark_on_image(mpDraw, results, img)

    img = draw_class_on_image(label, img)
    cv2.imshow("Image", img)
    if cv2.waitKey(1) == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
